{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaozomar/horseRaceDetection/blob/main/FinalProjectECS174.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if using weights file from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BTQHDSKIYOKM",
        "outputId": "45a02332-014e-4cae-9b71-eff32d8a625c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7d4ed9c7cd3a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if using weights file from drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r2h-ggxwxnaf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/akTwelve/Mask_RCNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-W6Bv7iC1jYa"
      },
      "outputs": [],
      "source": [
        "%cd Mask_RCNN\n",
        "!echo -e \"\\npixellib\" >> requirements.txt\n",
        "!pip3 install -r requirements.txt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.10/dist-packages/pixellib/instance/utils.py\n",
        "\n",
        "line 566/569: change `np.bool` to `bool`\n",
        "\n",
        "/content/Mask_RCNN/mrcnn/utils.py\n",
        "\n",
        "line 533/551/571/574: change `np.bool` to `bool`\n",
        "\n",
        "line 901/907: change `order=order` to `order=0`\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/pixellib/semantic/deeplab.py\n",
        "\n",
        "line 15: change `tensorflow.python.keras.layers` to `tensorflow.keras.layers`\n",
        "\n",
        "/content/Mask_RCNN/mrcnn/model.py\n",
        "\n",
        "line 1273: change `np.bool` to `bool`\n",
        "\n",
        "line 2141: change `from keras.utils.data_utils` to `from tensorflow.keras.utils`\n",
        "\n",
        "line 2355: change `multiprocessing.cpu_count()` to `1`\n",
        "\n",
        "restart session"
      ],
      "metadata": {
        "id": "f-DkxtySXHeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Mask_RCNN\n",
        "!python3 setup.py install\n",
        "%cd .."
      ],
      "metadata": {
        "collapsed": true,
        "id": "jJO85a-TXCWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_7lVUGZv9nBP"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/waleedka/coco.git\n",
        "%cd coco/PythonAPI\n",
        "!make\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEOsp4Kd-toY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import imgaug\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "# Import Mask RCNN\n",
        "import sys\n",
        "sys.path.insert(0, '/content/Mask_RCNN')\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "horse_class_id = 18\n",
        "\n",
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "class CocoConfig(Config):\n",
        "    \"\"\"Configuration for training on MS COCO.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the COCO dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Uncomment to train on 8 GPUs (default is 1)\n",
        "    # GPU_COUNT = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 80  # COCO has 80 classes\n",
        "\n",
        "class InferenceConfig(CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "\n",
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class CocoDataset(utils.Dataset):\n",
        "    def load_coco(self, dataset_dir, subset, year, class_ids=None,\n",
        "                  class_map=None, return_coco=False, auto_download=False):\n",
        "        \"\"\"Load a subset of the COCO dataset.\n",
        "        dataset_dir: The root directory of the COCO dataset.\n",
        "        subset: What to load (train, val, minival, valminusminival)\n",
        "        year: What dataset year to load (2014, 2017) as a string, not an integer\n",
        "        class_ids: If provided, only loads images that have the given classes.\n",
        "        class_map: TODO: Not implemented yet. Supports maping classes from\n",
        "            different datasets to the same class ID.\n",
        "        return_coco: If True, returns the COCO object.\n",
        "        auto_download: Automatically download and unzip MS-COCO images and annotations\n",
        "        \"\"\"\n",
        "\n",
        "        if auto_download is True:\n",
        "            self.auto_download(dataset_dir, subset, year)\n",
        "\n",
        "        coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, subset, year))\n",
        "        if subset == \"minival\" or subset == \"valminusminival\":\n",
        "            subset = \"val\"\n",
        "        image_dir = \"{}/{}{}\".format(dataset_dir, subset, year)\n",
        "\n",
        "        # Load all classes or a subset?\n",
        "        if not class_ids:\n",
        "            # All classes\n",
        "            class_ids = sorted(coco.getCatIds())\n",
        "\n",
        "        # All images or a subset?\n",
        "        if class_ids:\n",
        "            image_ids = []\n",
        "            for id in class_ids:\n",
        "                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
        "            # Remove duplicates\n",
        "            image_ids = list(set(image_ids))\n",
        "        else:\n",
        "            # All images\n",
        "            image_ids = list(coco.imgs.keys())\n",
        "\n",
        "        # Add classes\n",
        "        for i in class_ids:\n",
        "            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n",
        "\n",
        "        # Add images\n",
        "        for i in image_ids:\n",
        "            annotations = coco.loadAnns(coco.getAnnIds(imgIds=[i], catIds=class_ids, iscrowd=None))\n",
        "            if len(annotations) > 0:  # Only add images that contain the specified class\n",
        "                self.add_image(\n",
        "                    \"coco\", image_id=i,\n",
        "                    path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
        "                    width=coco.imgs[i][\"width\"],\n",
        "                    height=coco.imgs[i][\"height\"],\n",
        "                    annotations=annotations\n",
        "                )\n",
        "        if return_coco:\n",
        "            return coco\n",
        "\n",
        "    def auto_download(self, dataDir, dataType, dataYear):\n",
        "        \"\"\"Download the COCO dataset/annotations if requested.\n",
        "        dataDir: The root directory of the COCO dataset.\n",
        "        dataType: What to load (train, val, minival, valminusminival)\n",
        "        dataYear: What dataset year to load (2014, 2017) as a string, not an integer\n",
        "        Note:\n",
        "            For 2014, use \"train\", \"val\", \"minival\", or \"valminusminival\"\n",
        "            For 2017, only \"train\" and \"val\" annotations are available\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup paths and file names\n",
        "        if dataType == \"minival\" or dataType == \"valminusminival\":\n",
        "            imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n",
        "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n",
        "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n",
        "        else:\n",
        "            imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n",
        "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n",
        "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n",
        "        # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n",
        "\n",
        "        # Create main folder if it doesn't exist yet\n",
        "        if not os.path.exists(dataDir):\n",
        "            os.makedirs(dataDir)\n",
        "\n",
        "        # Download images if not available locally\n",
        "        if not os.path.exists(imgDir):\n",
        "            os.makedirs(imgDir)\n",
        "            print(\"Downloading images to \" + imgZipFile + \" ...\")\n",
        "            with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n",
        "                shutil.copyfileobj(resp, out)\n",
        "            print(\"... done downloading.\")\n",
        "            print(\"Unzipping \" + imgZipFile)\n",
        "            with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(dataDir)\n",
        "            print(\"... done unzipping\")\n",
        "        print(\"Will use images in \" + imgDir)\n",
        "\n",
        "        # Setup annotations data paths\n",
        "        annDir = \"{}/annotations\".format(dataDir)\n",
        "        if dataType == \"minival\":\n",
        "            annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n",
        "            annFile = \"{}/instances_minival2014.json\".format(annDir)\n",
        "            annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n",
        "            unZipDir = annDir\n",
        "        elif dataType == \"valminusminival\":\n",
        "            annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n",
        "            annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n",
        "            annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n",
        "            unZipDir = annDir\n",
        "        else:\n",
        "            annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n",
        "            annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n",
        "            annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n",
        "            unZipDir = dataDir\n",
        "        # print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n",
        "\n",
        "        # Download annotations if not available locally\n",
        "        if not os.path.exists(annDir):\n",
        "            os.makedirs(annDir)\n",
        "        if not os.path.exists(annFile):\n",
        "            if not os.path.exists(annZipFile):\n",
        "                print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
        "                with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
        "                    shutil.copyfileobj(resp, out)\n",
        "                print(\"... done downloading.\")\n",
        "            print(\"Unzipping \" + annZipFile)\n",
        "            with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(unZipDir)\n",
        "            print(\"... done unzipping\")\n",
        "        print(\"Will use annotations in \" + annFile)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Load instance masks for the given image.\n",
        "\n",
        "        Different datasets use different ways to store masks. This\n",
        "        function converts the different mask format to one format\n",
        "        in the form of a bitmap [height, width, instances].\n",
        "\n",
        "        Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a COCO image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"coco\":\n",
        "            return super(CocoDataset, self).load_mask(image_id)\n",
        "\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        annotations = self.image_info[image_id][\"annotations\"]\n",
        "        # Build mask of shape [height, width, instance_count] and list\n",
        "        # of class IDs that correspond to each channel of the mask.\n",
        "        for annotation in annotations:\n",
        "            class_id = self.map_source_class_id(\n",
        "                \"coco.{}\".format(annotation['category_id']))\n",
        "            if class_id:\n",
        "                m = self.annToMask(annotation, image_info[\"height\"],\n",
        "                                   image_info[\"width\"])\n",
        "                # Some objects are so small that they're less than 1 pixel area\n",
        "                # and end up rounded out. Skip those objects.\n",
        "                if m.max() < 1:\n",
        "                    continue\n",
        "                # Is it a crowd? If so, use a negative class ID.\n",
        "                if annotation['iscrowd']:\n",
        "                    # Use negative class ID for crowds\n",
        "                    class_id *= -1\n",
        "                    # For crowd masks, annToMask() sometimes returns a mask\n",
        "                    # smaller than the given dimensions. If so, resize it.\n",
        "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
        "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
        "                instance_masks.append(m)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        # Pack instance masks into an array\n",
        "        if class_ids:\n",
        "            mask = np.stack(instance_masks, axis=2).astype(bool)\n",
        "            class_ids = np.array(class_ids, dtype=np.int32)\n",
        "            return mask, class_ids\n",
        "        else:\n",
        "            # Call super class to return an empty mask\n",
        "            return super(CocoDataset, self).load_mask(image_id)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"coco\":\n",
        "            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n",
        "        else:\n",
        "            super(CocoDataset, self).image_reference(image_id)\n",
        "\n",
        "    # The following two functions are from pycocotools with a few changes.\n",
        "\n",
        "    def annToRLE(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        segm = ann['segmentation']\n",
        "        if isinstance(segm, list):\n",
        "            # polygon -- a single object might consist of multiple parts\n",
        "            # we merge all parts into one mask rle code\n",
        "            rles = maskUtils.frPyObjects(segm, height, width)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif isinstance(segm['counts'], list):\n",
        "            # uncompressed RLE\n",
        "            rle = maskUtils.frPyObjects(segm, height, width)\n",
        "        else:\n",
        "            # rle\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "\n",
        "    def annToMask(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        rle = self.annToRLE(ann, height, width)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX7v2Iqx_S8s",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Train\n",
        "############################################################\n",
        "\n",
        "# Configurations\n",
        "config = CocoConfig()\n",
        "# config.display()\n",
        "\n",
        "# Create model\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=\"./logs\")\n",
        "\n",
        "# Load weights\n",
        "model_path = model.get_imagenet_weights()\n",
        "print(\"Loading weights \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "dataset_train = CocoDataset()\n",
        "dataset_train.load_coco(\"./dataset\", \"train\", year=\"2017\", class_ids=[horse_class_id], auto_download=True)\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = CocoDataset()\n",
        "dataset_val.load_coco(\"./dataset\", \"val\", year=\"2017\", class_ids=[horse_class_id], auto_download=True)\n",
        "dataset_val.prepare()\n",
        "\n",
        "# Image Augmentation\n",
        "# Right/Left flip 50% of the time\n",
        "augmentation = imgaug.augmenters.Fliplr(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHiict5QFl94",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(\"Training\")\n",
        "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE,\n",
        "                    epochs=20, layers='heads', augmentation=augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"./final_weights.h5\""
      ],
      "metadata": {
        "id": "22qAJDlAWia_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#  Apply\n",
        "############################################################\n",
        "\n",
        "import pixellib\n",
        "from pixellib.semantic import semantic_segmentation\n",
        "from pixellib.instance import instance_segmentation\n",
        "\n",
        "def pixellibCoco(pictureFile):\n",
        "    # Open a segment model of Mask R_CNN model trained on Microsoft Coco dataset\n",
        "    segment_image_ist = instance_segmentation()\n",
        "    segment_image_ist.load_model(MODEL_PATH)\n",
        "    results, segoverlay = segment_image_ist.segmentImage(pictureFile, output_image_name = \"instance_\"+pictureFile, show_bboxes = True)\n",
        "    return results, segoverlay\n",
        "\n",
        "def findWinner(results, direction):\n",
        "    rois = results['rois']\n",
        "    class_ids = results['class_ids']\n",
        "    masks = results['masks']\n",
        "\n",
        "    winning_horse_i = -1\n",
        "    if direction == 'left':\n",
        "        winning_horse_x = 1000\n",
        "    else:\n",
        "        winning_horse_x = -1000\n",
        "\n",
        "    for i, class_id in enumerate(class_ids):\n",
        "        if class_id == horse_class_id:\n",
        "            if direction == 'left':\n",
        "                curr_x = rois[i][1]\n",
        "            else:\n",
        "                curr_x = rois[i][3]\n",
        "            if direction == 'left' and curr_x < winning_horse_x or direction == 'right' and curr_x > winning_horse_x:\n",
        "                winning_horse_x = curr_x\n",
        "                winning_horse_i = i\n",
        "    if winning_horse_i != -1:\n",
        "        return masks[:, :, winning_horse_i], winning_horse_x\n",
        "    print(\"no horse\")\n",
        "\n",
        "def overlayMask(image, mask):\n",
        "    color = [255, 215, 0]  # Gold\n",
        "    color_mask = np.zeros_like(image)\n",
        "    for i in range(3):\n",
        "        color_mask[:, :, i] = mask * color[i]\n",
        "    return cv2.addWeighted(image, 1.0, color_mask, 0.5, 0)"
      ],
      "metadata": {
        "id": "D0PdSOwDZ7Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pictureFile = \"01012018R3C2.png\" # left\n",
        "# pictureFile = \"01012018R3C5.png\" # left\n",
        "# pictureFile = \"01012018R3C7.png\" # left\n",
        "# pictureFile = \"01012019R1C1.png\" # right\n",
        "# pictureFile = \"01022019R2C5.png\" # left\n",
        "pictureFile = \"01022021R4C3.png\" # left\n",
        "# pictureFile = \"01012019R3C7.png\" # right\n",
        "# pictureFile = \"01012020R1C8.png\" # right\n",
        "race_direction = 'left'"
      ],
      "metadata": {
        "id": "CP3iKt3HaM0m",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, segoverlay = pixellibCoco(pictureFile)\n",
        "mask, winner_x = findWinner(results, race_direction)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Pk57EU7HJRz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(5, 8))\n",
        "\n",
        "img = cv2.imread(pictureFile, cv2.IMREAD_COLOR)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "fig.add_subplot(3, 1, 1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original Picture: \"+pictureFile)\n",
        "\n",
        "segoverlay = cv2.cvtColor(segoverlay, cv2.COLOR_BGR2RGB)\n",
        "fig.add_subplot(3, 1, 2)\n",
        "plt.imshow(segoverlay)\n",
        "plt.axis('off')\n",
        "plt.title(\"Segmentation Overlay\")\n",
        "\n",
        "winoverlay = overlayMask(img, mask)\n",
        "fig.add_subplot(3, 1, 3)\n",
        "plt.imshow(winoverlay)\n",
        "plt.axvline(x=winner_x, color='red', linewidth=2)\n",
        "plt.axis('off')\n",
        "plt.title(\"Winner Overlay\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rybaaw0sahB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}